{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8588840,"sourceType":"datasetVersion","datasetId":5137255}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 📊 AI/ML Job Market Analysis — Real LinkedIn Dataset Project\n\nThis is my first full data analysis project where I tried to make sense of 800+ real AI/ML job listings scraped from LinkedIn (via Kaggle).  \nI didn’t want to just run code — I wanted to understand **what the hiring scene actually looks like** for people entering this field.\n\nI broke the whole process into 6 versions — each one focusing on cleaning, exploring, and asking better questions than the last.  \nIt’s not perfect, but I learned more with each step.\n\n> I’ve documented everything version by version — including challenges, fixes, learnings, and what surprised me.","metadata":{}},{"cell_type":"markdown","source":"## Notebook Version: v1  \n**Focus**: Dataset loading and basic structural preview  \n\nThis notebook is part of a versioned project exploring trends in AI/ML job postings in the U.S.  \nThis version focuses on loading the dataset, checking its structure, and identifying surface-level issues.\n","metadata":{}},{"cell_type":"code","source":"#importing the necessary libraries\nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.152029Z","iopub.execute_input":"2025-08-06T10:58:20.152294Z","iopub.status.idle":"2025-08-06T10:58:20.487609Z","shell.execute_reply.started":"2025-08-06T10:58:20.152265Z","shell.execute_reply":"2025-08-06T10:58:20.486771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Overview\n\n- Source: Kaggle – AI and ML Job Listings USA  \n- File path: `/kaggle/input/ai-and-ml-job-listings-usa/ai_ml_jobs_linkedin.csv","metadata":{}},{"cell_type":"markdown","source":"## Load and Preview Data\n\nLoading the dataset into a DataFrame and preview the structure to understand its basic layout.\n","metadata":{}},{"cell_type":"code","source":"# Load the dataset\nus_jobs_df = pd.read_csv('/kaggle/input/ai-and-ml-job-listings-usa/ai_ml_jobs_linkedin.csv')\n\n# Create a working copy\njobs_df = us_jobs_df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.489469Z","iopub.execute_input":"2025-08-06T10:58:20.489854Z","iopub.status.idle":"2025-08-06T10:58:20.613611Z","shell.execute_reply.started":"2025-08-06T10:58:20.489800Z","shell.execute_reply":"2025-08-06T10:58:20.612824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preview first 2 rows\njobs_df.head(2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.614506Z","iopub.execute_input":"2025-08-06T10:58:20.614801Z","iopub.status.idle":"2025-08-06T10:58:20.640806Z","shell.execute_reply.started":"2025-08-06T10:58:20.614775Z","shell.execute_reply":"2025-08-06T10:58:20.640049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check dataset shape\nprint(f\"Rows: {jobs_df.shape[0]}, Columns: {jobs_df.shape[1]}\")\n\n# Data types and non-null info\njobs_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.641720Z","iopub.execute_input":"2025-08-06T10:58:20.642034Z","iopub.status.idle":"2025-08-06T10:58:20.667675Z","shell.execute_reply.started":"2025-08-06T10:58:20.642006Z","shell.execute_reply":"2025-08-06T10:58:20.666805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Summary stats for numeric columns\njobs_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.668604Z","iopub.execute_input":"2025-08-06T10:58:20.668966Z","iopub.status.idle":"2025-08-06T10:58:20.707479Z","shell.execute_reply.started":"2025-08-06T10:58:20.668944Z","shell.execute_reply":"2025-08-06T10:58:20.706639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initial Observations and Notes\n\n- The dataset contains **862 rows** and **10 columns**.\n- Some columns such as `companyName`, `publishedAt`, and `sector` contain missing values.\n- Columns like `applicationsCount` and `publishedAt` may need data type conversions in the next version.\n- No immediate data loading issues were encountered.\n","metadata":{}},{"cell_type":"markdown","source":"## Notebook Version: v2  \n**Focus**: Data Cleaning and Formatting  \n \nThis version focuses on cleaning the dataset, handling missing values, renaming columns, correcting data types, and preparing the data for analysis.\n","metadata":{}},{"cell_type":"code","source":"#previewing the data again\njobs_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.708377Z","iopub.execute_input":"2025-08-06T10:58:20.708653Z","iopub.status.idle":"2025-08-06T10:58:20.719555Z","shell.execute_reply.started":"2025-08-06T10:58:20.708627Z","shell.execute_reply":"2025-08-06T10:58:20.718836Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handling missing/null values","metadata":{}},{"cell_type":"code","source":"#checking for null values if any\njobs_df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.722072Z","iopub.execute_input":"2025-08-06T10:58:20.722297Z","iopub.status.idle":"2025-08-06T10:58:20.740911Z","shell.execute_reply.started":"2025-08-06T10:58:20.722278Z","shell.execute_reply":"2025-08-06T10:58:20.740023Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Type Fix","metadata":{}},{"cell_type":"code","source":"#handling null values\n\n#filling the null values in columns 'companyName' and 'experienceLevel' as 'Unknown'\njobs_df[['companyName','sector']] = jobs_df[['companyName','sector']].fillna('Unknown')\n\n#handling the null value for column 'publishedAt' using ffill() assuming that the post has been updated nearly at that date\njobs_df['publishedAt'] = jobs_df['publishedAt'].fillna(method='ffill')\n\n#check if null value still exists\njobs_df.isna().sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.741657Z","iopub.execute_input":"2025-08-06T10:58:20.741940Z","iopub.status.idle":"2025-08-06T10:58:20.768504Z","shell.execute_reply.started":"2025-08-06T10:58:20.741918Z","shell.execute_reply":"2025-08-06T10:58:20.767633Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### NOTE:\nFilled publishedAt using forward fill to maintain temporal continuity, assuming listings are updated close to previous records.","metadata":{}},{"cell_type":"code","source":"#checking for the datatypes \njobs_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.770046Z","iopub.execute_input":"2025-08-06T10:58:20.770351Z","iopub.status.idle":"2025-08-06T10:58:20.782702Z","shell.execute_reply.started":"2025-08-06T10:58:20.770325Z","shell.execute_reply":"2025-08-06T10:58:20.781889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# converting 'publishedAt' into datetime data type  \njobs_df['publishedAt'] = pd.to_datetime(jobs_df['publishedAt'])\n\n# converting 'applicationsCount' into integer data type\n#first we need to extract the count of the applications \njobs_df['applicationsCount'] = jobs_df['applicationsCount'].str.extract(r'(\\d+)')[0]\n\n#now convert the 'applicationsCount' dtype to numeric\njobs_df['applicationsCount'] = pd.to_numeric(jobs_df['applicationsCount'])\njobs_df.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.783573Z","iopub.execute_input":"2025-08-06T10:58:20.783877Z","iopub.status.idle":"2025-08-06T10:58:20.814211Z","shell.execute_reply.started":"2025-08-06T10:58:20.783852Z","shell.execute_reply":"2025-08-06T10:58:20.813395Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Removing the columns that are not useful for my analysis","metadata":{}},{"cell_type":"code","source":"#making a new df to store only the columns that are useful for my analysis\n\nupdated_jobs = jobs_df.drop(columns=['description','sector','workType'])\nupdated_jobs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.815108Z","iopub.execute_input":"2025-08-06T10:58:20.815346Z","iopub.status.idle":"2025-08-06T10:58:20.841923Z","shell.execute_reply.started":"2025-08-06T10:58:20.815328Z","shell.execute_reply":"2025-08-06T10:58:20.841152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Duplicate Check and Removal","metadata":{}},{"cell_type":"code","source":"# checking the duplicate values that exists (based on all columns)\n# updated_jobs.duplicated().sum()\nupdated_jobs[updated_jobs.duplicated()]\n\n# dropping the duplicated values\nupdated_jobs.drop_duplicates(inplace=True)\n\n# check if any row exist that have same title,companyName, location and publishedAt\nupdated_jobs.duplicated(subset=['title', 'companyName', 'location', 'publishedAt']).sum()\n\n# removing the dupliacted values\nduplicate_vals = updated_jobs.duplicated(subset=['title', 'companyName', 'location', 'publishedAt'])\nupdated_jobs = updated_jobs[~duplicate_vals].copy()\n\n#resetting the index after droppingt the duplicate values\nupdated_jobs.reset_index(drop=True,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.842839Z","iopub.execute_input":"2025-08-06T10:58:20.843134Z","iopub.status.idle":"2025-08-06T10:58:20.864798Z","shell.execute_reply.started":"2025-08-06T10:58:20.843107Z","shell.execute_reply":"2025-08-06T10:58:20.864110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Whitespace Stripping \n\n","metadata":{}},{"cell_type":"code","source":"#stripping the whitespaces if any, from the string based columns\n\nfor col in ['title','companyName','location','experienceLevel','contractType']:\n    updated_jobs[col] = updated_jobs[col].str.strip()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.865703Z","iopub.execute_input":"2025-08-06T10:58:20.865936Z","iopub.status.idle":"2025-08-06T10:58:20.882751Z","shell.execute_reply.started":"2025-08-06T10:58:20.865916Z","shell.execute_reply":"2025-08-06T10:58:20.881870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Category Cleaning","metadata":{}},{"cell_type":"code","source":"#1. title\n# for consistency I am converting the titles into title case\nupdated_jobs['title'] = updated_jobs['title'].str.title()\n\n#check if the function is applied properly\nupdated_jobs['title'].head(3)\n\n#2. location\n# I will be splitting the location column into two parts: one is for city and other is for state\nlocation_split = updated_jobs['location'].str.split(',',n=1,expand=True)\n\n#adding the city column\nupdated_jobs['city'] = location_split[0].str.strip()\n\n#adding the state column\nupdated_jobs['state'] = location_split[1].str.strip()\n\n#check if any null value has been added due to the above two columns\nupdated_jobs.isna().sum()\n\n#handle the null values\nupdated_jobs['state'] = updated_jobs['state'].fillna('Unknown')\n\n#rechecking for null values\nupdated_jobs.isna().sum()\n\n#removing the location column as it is no more useful\nupdated_jobs.drop('location',axis='columns',inplace=True)\n\n#3. publishedAt\n# I will be asplitting this column also into two parts year and month (day is not useful)\n\nupdated_jobs['year'] = updated_jobs['publishedAt'].dt.year\nupdated_jobs['month'] = updated_jobs['publishedAt'].dt.month\n\n#dropping the publishedAt column because it is not useful\nupdated_jobs.drop('publishedAt',axis='columns',inplace=True)\nupdated_jobs.columns\n\n#4. companyName\n# converting the company's name into title case so that it remains consistent throughout\nupdated_jobs['companyName'] = updated_jobs['companyName'].str.title()\n\n#check if the change has been made properly\nupdated_jobs['companyName'].head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.883710Z","iopub.execute_input":"2025-08-06T10:58:20.884043Z","iopub.status.idle":"2025-08-06T10:58:20.917224Z","shell.execute_reply.started":"2025-08-06T10:58:20.884016Z","shell.execute_reply":"2025-08-06T10:58:20.916238Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Cleaning and Structuring Summary\n\nIn this version, I focused on cleaning and structuring the dataset to prepare it for meaningful analysis. The original dataset had multiple inconsistencies and mixed-format fields which could hinder exploration and insights.\n\n## 🚀 Key actions\n- Selected 7 relevant columns for the analysis.\n- Cleaned categorical columns (`title`, `companyName`, `location`) for consistency.\n- Split complex fields like `location` and `publishedAt` into simpler, analyzable components (city, state, year, month).\n- Handled missing values in `state` by filling with \"Unknown\".\n\n## ⚠️ Challenges\n- Some job titles were overly specific or inconsistent (e.g., different casing, role modifiers). I resolved this with title casing but might need more grouping later.\n- The `location` field didn’t follow a uniform format in all rows — some were missing state info, which led to NaN values after splitting.\n- The `publishedAt` field contained full timestamps, which were not useful at this stage. It took care to isolate only the useful components (year/month) without losing meaning.\n\n## 🎯 Learnings\n- Even basic string cleaning and formatting (like `.str.title()` or `.str.strip()`) can greatly improve consistency in the dataset.\n- Breaking down complex columns (like `location` and `publishedAt`) can make future analysis smoother and more insightful.\n- It's important to analyze columns one by one instead of applying generic cleaning — each column may need unique handling.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Notebook Version: v3  \n**Focus**: Exploratory Data Analysis (EDA)\n\nThis version focuses on asking structured and slightly deeper questions to understand the dataset better.  \nI'm primarily focusing on categorical patterns, hiring distributions, and application behavior.  \nWe'll go from basic univariate counts to intermediate bivariate groupings (without visuals, which are reserved for v4).\n\n> Note: `title` and `sector` are *not* taken up in this version intentionally.  \n> - `title` is too noisy to analyze meaningfully without cleanup — we’ll handle that in **v5**.  \n> - `sector` is reserved for **v5** as well, to avoid overloading this version and to keep v3 beginner-friendly.\n\n","metadata":{}},{"cell_type":"markdown","source":"### 1. Exploring Unique Values in Categorical Columns","metadata":{}},{"cell_type":"code","source":"#finding number of unique values in categorical columns\nprint('Unique values in categorical column:')\nprint(updated_jobs[['contractType','experienceLevel','month','year']].nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.918200Z","iopub.execute_input":"2025-08-06T10:58:20.918533Z","iopub.status.idle":"2025-08-06T10:58:20.935833Z","shell.execute_reply.started":"2025-08-06T10:58:20.918465Z","shell.execute_reply":"2025-08-06T10:58:20.934873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Top 10 Most Common Job Titles","metadata":{}},{"cell_type":"code","source":"#top 10 most common job titles\ncommon_title = updated_jobs['title'].value_counts().head(10)\nprint('Top 10 most common job titles')\nprint(common_title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.937008Z","iopub.execute_input":"2025-08-06T10:58:20.937471Z","iopub.status.idle":"2025-08-06T10:58:20.956665Z","shell.execute_reply.started":"2025-08-06T10:58:20.937451Z","shell.execute_reply":"2025-08-06T10:58:20.955742Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This gives a sense of which roles are being advertised the most — though detailed title analysis will be taken in v5.\n","metadata":{}},{"cell_type":"markdown","source":"###  3. Companies Posting the Most Jobs","metadata":{}},{"cell_type":"code","source":"#companies that have posted the most job listings\nprint('Companies that have posted the most job listings')\nprint(updated_jobs['companyName'].value_counts().head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.957657Z","iopub.execute_input":"2025-08-06T10:58:20.957928Z","iopub.status.idle":"2025-08-06T10:58:20.972542Z","shell.execute_reply.started":"2025-08-06T10:58:20.957903Z","shell.execute_reply":"2025-08-06T10:58:20.971680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Companies with the most job listings often reflect dominant hiring brands in the market.\n","metadata":{}},{"cell_type":"markdown","source":"###  4. Top 5 Hiring Cities (with Cleaning)","metadata":{}},{"cell_type":"code","source":"#cities that are hiring the most(top 5)\n\n#NOTE: alot of records have United States as a city but that is a wrong value, thus replacing it with 'Unknown'\nupdated_jobs['city'] = updated_jobs['city'].replace('United States','Unknown')\nupdated_jobs['city'].value_counts()\n\n#NOTE: majority of companies have not entered the city, thus we will be ignoring it and will show the actual city names\nhiring_cities = updated_jobs['city'][updated_jobs['city'] != 'Unknown']\nhiring_cities.reset_index(drop=True, inplace=True)\nprint('Top 5 cities in US that are hiring the most')\nprint(hiring_cities.value_counts().head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.973382Z","iopub.execute_input":"2025-08-06T10:58:20.973705Z","iopub.status.idle":"2025-08-06T10:58:20.995450Z","shell.execute_reply.started":"2025-08-06T10:58:20.973678Z","shell.execute_reply":"2025-08-06T10:58:20.994552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I noticed that many job listings have 'United States' or missing city data, so I cleaned it for more realistic counts.\n(Probably missed in v2 while cleaning the data)","metadata":{}},{"cell_type":"markdown","source":"###  5. Most Common Contract Type & Experience Level","metadata":{}},{"cell_type":"code","source":"#most common contractType\nprint('Most common contract type: ')\nprint(updated_jobs['contractType'].value_counts().head(1).index[0])\nprint()\n\n#experience level that is highest in demand\nprint('Experience level that is highest in demand ')\nprint(updated_jobs['experienceLevel'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:20.996415Z","iopub.execute_input":"2025-08-06T10:58:20.996774Z","iopub.status.idle":"2025-08-06T10:58:21.015706Z","shell.execute_reply.started":"2025-08-06T10:58:20.996748Z","shell.execute_reply":"2025-08-06T10:58:21.014875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Basic univariate checks to understand the dominant job types and demanded experience levels.\n","metadata":{}},{"cell_type":"markdown","source":"###  6. Average Application Count","metadata":{}},{"cell_type":"code","source":"#average of application counts\nprint('Average of application counts:')\nprint(updated_jobs['applicationsCount'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.016724Z","iopub.execute_input":"2025-08-06T10:58:21.017050Z","iopub.status.idle":"2025-08-06T10:58:21.031031Z","shell.execute_reply.started":"2025-08-06T10:58:21.017024Z","shell.execute_reply":"2025-08-06T10:58:21.030282Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This shows how saturated the job market is — a very high mean might suggest few postings with extreme competition.\n","metadata":{}},{"cell_type":"markdown","source":"### 7. Company with Highest/Lowest Application Count","metadata":{}},{"cell_type":"code","source":"#company that recieved highest and lowest number of applications\n\n#grouping the company with the total number of application count\njob_app_count = updated_jobs.groupby('companyName').agg({'applicationsCount':'sum'})\n\n#extracting the max and min count\nmax_val = job_app_count['applicationsCount'].max()\nmin_val = job_app_count['applicationsCount'].min()\n\n#extracting the company names\nprint(\"Company that recieved highest applications\")\nhighest_company = job_app_count[job_app_count['applicationsCount'] == max_val]\nprint(highest_company)\nprint()\n\nlowest_company = job_app_count[job_app_count['applicationsCount'] == min_val]\nprint(\"Top 5 companies that got lowest application count\")\nprint(lowest_company.head())\nprint()\n#NOTE! : there are alot of companies that have got the minimum(25) number of applications, so showing only 5 of them","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.031913Z","iopub.execute_input":"2025-08-06T10:58:21.032219Z","iopub.status.idle":"2025-08-06T10:58:21.053074Z","shell.execute_reply.started":"2025-08-06T10:58:21.032170Z","shell.execute_reply":"2025-08-06T10:58:21.052211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This indicates which companies attract more attention from applicants — maybe due to reputation or role type.\n","metadata":{}},{"cell_type":"markdown","source":"### 8. Application Count by Experience Level","metadata":{}},{"cell_type":"code","source":"#application count distribution by experience level\nprint('Application count distribution by experience level')\nexp_app_count = updated_jobs.groupby('experienceLevel').agg({'applicationsCount':'sum'})\nprint(exp_app_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.058080Z","iopub.execute_input":"2025-08-06T10:58:21.058796Z","iopub.status.idle":"2025-08-06T10:58:21.071042Z","shell.execute_reply.started":"2025-08-06T10:58:21.058770Z","shell.execute_reply":"2025-08-06T10:58:21.070061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Helpful to understand if juniors or seniors are attracting more applications.\n","metadata":{}},{"cell_type":"markdown","source":"### 9. Contract Types Getting the Most Applications","metadata":{}},{"cell_type":"code","source":"#contractType that are getting the highest number of applications\nprint('Contract type that are getting the highest number of applications')\ncontract_app_count = updated_jobs.groupby('contractType').agg({'applicationsCount':'sum'})\nhighest_count = contract_app_count['applicationsCount'].max()\nhighest_contract_val = contract_app_count[contract_app_count['applicationsCount']==highest_count]\nprint(highest_contract_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.072201Z","iopub.execute_input":"2025-08-06T10:58:21.072489Z","iopub.status.idle":"2025-08-06T10:58:21.091104Z","shell.execute_reply.started":"2025-08-06T10:58:21.072462Z","shell.execute_reply":"2025-08-06T10:58:21.090221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Applicants are applying more for full time contract type as compared to other types of contract","metadata":{}},{"cell_type":"markdown","source":"### 10. Experience Level vs Contract Type ","metadata":{}},{"cell_type":"code","source":"#which experience level are linked more with which contract type\nexp_contract = updated_jobs.groupby(['experienceLevel', 'contractType']).size().unstack().fillna(0)\nprint(\"Experience vs Contract Type distribution:\")\nprint(exp_contract)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.092048Z","iopub.execute_input":"2025-08-06T10:58:21.092978Z","iopub.status.idle":"2025-08-06T10:58:21.124461Z","shell.execute_reply.started":"2025-08-06T10:58:21.092957Z","shell.execute_reply":"2025-08-06T10:58:21.123505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cross-sectional view of how contract types differ across experience levels. This helps in understanding how experience level varies with contract type","metadata":{}},{"cell_type":"markdown","source":"### 11. Underperforming Contract Types","metadata":{}},{"cell_type":"code","source":"#Contract types with high postings but fewer average applications:\n\navg_app_per_contract = updated_jobs.groupby('contractType').agg({\n    'applicationsCount': 'mean',\n    'contractType': 'count'\n}).rename(columns={'contractType': 'jobCount'}).sort_values(by='applicationsCount')\nprint(\"Avg applications per contract type vs job count:\")\nprint(avg_app_per_contract)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.125294Z","iopub.execute_input":"2025-08-06T10:58:21.125596Z","iopub.status.idle":"2025-08-06T10:58:21.137127Z","shell.execute_reply.started":"2025-08-06T10:58:21.125570Z","shell.execute_reply":"2025-08-06T10:58:21.136326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This analysis shows which contract types might be oversupplied or under-attractive — useful for recruiters or job portals.\n","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis Summary – Version 3\n\nIn this version, I focused on exploring the dataset more deeply using beginner to intermediate level EDA (without any visuals).  \nThe goal was to understand how different categorical features like experience level, contract type, city, and applications behave — both on their own and together.\n\n\n## 🔍 What I Did\n\n- Checked unique values for key categorical columns: `contractType`, `experienceLevel`, `month`, and `year`.\n- Found out which companies posted the most jobs and which cities are hiring the most.\n- Looked at average application counts, plus which companies got the highest and lowest applications, and which contract types are getting the most interest.\n- Grouped experience levels and contract types to see how they relate to each other.\n- Identified which job types might be oversaturated (that is, lots of postings but not many applications on average).\n\n\n## ⚠️ What I Didn’t Cover\n\n- Skipped the `title` column for now because it’s just too messy — planning to clean and analyze job titles in v5 when I dive into deeper title/trend analysis.\n- Left out the `sector` column to keep this version beginner-friendly and focused. That'll be part of v5 too.\n\n\n## 🎯 What I Learned\n\n- You can pull out a lot of insights just by grouping and aggregating columns — no fancy plots needed.\n- Application counts alone tell a lot about what job types are getting attraction, and which ones most people are ignoring.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Notebook Version: v4  \n**Focus**: Visual Exploration & Useful Hiring Trends\n\nThis version builds on the cleaned dataset and focuses entirely on meaningful visualizations using Matplotlib and Seaborn.\n\nThe aim here is not to plot everything possible — but to highlight the kind of trends that would actually help:\n- **Job seekers**: spot hiring hotspots, application behavior, and target companies\n- **Recruiters**: benchmark trends, see market competition, and hiring patterns\n\nThe charts cover:\n- Top hiring companies\n- Contract type and experience level preferences\n- Sector-wise demand (basic view)\n- State-wise hiring trends\n- Job posting activity over time\n- Application count patterns\n- Company + state combinations to show where hiring is happening\n\n> ⚠️ Note: I’ve skipped anything related to `title` and detailed `sector` analysis for now — both need cleanup, and that’ll be handled in **Version 5**.\n","metadata":{}},{"cell_type":"code","source":"#importing the libraries for visulaisations\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:21.137988Z","iopub.execute_input":"2025-08-06T10:58:21.138276Z","iopub.status.idle":"2025-08-06T10:58:22.135880Z","shell.execute_reply.started":"2025-08-06T10:58:21.138248Z","shell.execute_reply":"2025-08-06T10:58:22.135031Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.  Top Hiring Companies","metadata":{}},{"cell_type":"code","source":"# which 10 companies are hiring the most\n\ntop_hiring = updated_jobs['companyName'].value_counts().head(10).reset_index()\ntop_hiring.columns = ['companyName','noOfJobs']\n\n#plotting the chart\nax = sns.barplot(data=top_hiring,x='noOfJobs',y='companyName',palette='crest')\nplt.title('Top 10 hiring companies')\nplt.xlabel('Company Names')\nplt.ylabel('No of Jobs Offered by Companies')\nfor container in ax.containers:\n    ax.bar_label(container,padding=1)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:22.136703Z","iopub.execute_input":"2025-08-06T10:58:22.137055Z","iopub.status.idle":"2025-08-06T10:58:22.467652Z","shell.execute_reply.started":"2025-08-06T10:58:22.137027Z","shell.execute_reply":"2025-08-06T10:58:22.466692Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Helps job seekers target high-opportunity employers\n\n- Helps recruiters benchmark hiring volume","metadata":{}},{"cell_type":"markdown","source":"### 2. Contract Type Trends","metadata":{}},{"cell_type":"code","source":"# how are jobs distributed across different contract types (e.g., Full-time, Contract)?\n\nax = sns.countplot(data=updated_jobs,x='contractType',palette='crest')\n\nplt.title('Contract Type Trends')\nplt.xlabel('Type of Contract')\nplt.ylabel('No of Job Listings')\n\nfor container in ax.containers:\n    ax.bar_label(container, padding=1)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:22.468650Z","iopub.execute_input":"2025-08-06T10:58:22.469056Z","iopub.status.idle":"2025-08-06T10:58:22.645796Z","shell.execute_reply.started":"2025-08-06T10:58:22.469020Z","shell.execute_reply":"2025-08-06T10:58:22.644879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Shows the nature of job availability in the market\n\n- Recruiters can benchmark contract vs full-time usage","metadata":{}},{"cell_type":"markdown","source":"### 3. Experience Level Demand","metadata":{}},{"cell_type":"code","source":"# which experience levels are most in demand?\n\nax = sns.countplot(data=updated_jobs, y='experienceLevel',palette='crest')\nplt.title('Experience Level Demand')\nplt.xlabel('Number of Job Listings')\nplt.ylabel('Experience Levels')\n\nfor container in ax.containers:\n    ax.bar_label(container,padding=1)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:22.646783Z","iopub.execute_input":"2025-08-06T10:58:22.647213Z","iopub.status.idle":"2025-08-06T10:58:22.932160Z","shell.execute_reply.started":"2025-08-06T10:58:22.647184Z","shell.execute_reply":"2025-08-06T10:58:22.931253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers can position themselves accordingly\n\n- Recruiters can validate if they're aligned with market","metadata":{}},{"cell_type":"markdown","source":"### 4. Sector-wise Job Distribution","metadata":{}},{"cell_type":"code","source":"# which 10 sectors have the highest number of listings?\n\nsector_jobs = jobs_df['sector'].value_counts().head(10).reset_index()\nsector_jobs.columns = ['sector','jobCount']\n\nax = sns.barplot(data=sector_jobs, x='jobCount',y='sector',palette='crest')\nplt.title('Sector-wise Job Distribution')\nplt.ylabel('Sectors')\nplt.xlabel('Number of Job Listings')\n\nfor container in ax.containers:\n    ax.bar_label(container,padding=1)\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:22.933285Z","iopub.execute_input":"2025-08-06T10:58:22.933581Z","iopub.status.idle":"2025-08-06T10:58:23.219245Z","shell.execute_reply.started":"2025-08-06T10:58:22.933556Z","shell.execute_reply":"2025-08-06T10:58:23.218366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers see which industries have the most job openings\n\n- Recruiters get a sense of how active their industry is in hiring","metadata":{}},{"cell_type":"markdown","source":"### 5. Job Postings Over Time","metadata":{}},{"cell_type":"code","source":"# how has the number of listings changed over months/years?\n\n#extracting the month and year from the date\njobs_df['year_month'] = jobs_df['publishedAt'].dt.to_period('M').astype('str')\n\n# counting the values\npostings = jobs_df['year_month'].value_counts().sort_index()\npostings = postings.reset_index()\npostings.columns = ['year_month','jobPostings']\n\nsns.lineplot(data=postings, x='year_month', y='jobPostings', palette='crest', marker='o')\nplt.title('Job Postings Over Time')\nplt.xlabel('Time period')\nplt.ylabel('Number of Job Listings')\nplt.grid(True)\nplt.xticks(rotation = 45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:23.220148Z","iopub.execute_input":"2025-08-06T10:58:23.220376Z","iopub.status.idle":"2025-08-06T10:58:23.476847Z","shell.execute_reply.started":"2025-08-06T10:58:23.220358Z","shell.execute_reply":"2025-08-06T10:58:23.475972Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers can time their applications better\n\n- Recruiters can plan campaigns around hiring peaks","metadata":{}},{"cell_type":"markdown","source":"### 6. Top 10 Hiring Locations (States Only)","metadata":{}},{"cell_type":"code","source":"# states column have 'Unknown' and 'United States' as value which needs to be handled first\nupdated_jobs.state.unique()\n\n# removing the 'unknown' and 'united states' value from the column\nstate_jobs = updated_jobs[~updated_jobs['state'].isin(['Unknown', 'United States'])].copy()\ntop_states = state_jobs['state'].value_counts().head(10)\ntop_states = top_states.reset_index()\ntop_states.columns = ['state','jobCount']\n\n#plotting the chart\nax = sns.barplot(data=top_states, x='state', y='jobCount', palette='crest')\nplt.title('Top 10 Hiring Locations(state-wise)')\nplt.ylabel('Number of Job Listing')\nplt.xlabel('States')\n\nfor container in ax.containers:\n    ax.bar_label(container,padding=1)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:23.477566Z","iopub.execute_input":"2025-08-06T10:58:23.477775Z","iopub.status.idle":"2025-08-06T10:58:23.703012Z","shell.execute_reply.started":"2025-08-06T10:58:23.477759Z","shell.execute_reply":"2025-08-06T10:58:23.702203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers can focus on high-demand regions\n\n- Recruiters can identify competitive hiring zones","metadata":{}},{"cell_type":"markdown","source":"### 7. Application Count Distribution","metadata":{}},{"cell_type":"code","source":"# what is the overall spread of application counts across listings?\nsns.histplot(data=updated_jobs, x='applicationsCount', bins=40, kde=True)\n\nplt.title('Distribution of Application Counts per Listing')\nplt.xlabel('Number of Applications')\nplt.ylabel('Number of Listings')\nplt.grid(True)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:23.703935Z","iopub.execute_input":"2025-08-06T10:58:23.704167Z","iopub.status.idle":"2025-08-06T10:58:24.006102Z","shell.execute_reply.started":"2025-08-06T10:58:23.704149Z","shell.execute_reply":"2025-08-06T10:58:24.005283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers get a sense of competition\n\n- Recruiters learn which roles get more attention","metadata":{}},{"cell_type":"markdown","source":"### 8. Total Applications per Sector","metadata":{}},{"cell_type":"code","source":"# Which sectors receive more applications in total?\n\nsector_app = jobs_df.groupby('sector',as_index=False).agg({'applicationsCount':'sum'})\nsector_app = sector_app.sort_values(by='applicationsCount', ascending=False).head(10).reset_index()\n\nax = sns.barplot(data=sector_app, y='sector', x='applicationsCount', palette='crest')\nplt.title('Total applications per sector')\nplt.xlabel('Number of applications')\nplt.ylabel('Sectors')\n\nfor container in ax.containers:\n    ax.bar_label(container,padding=1)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:24.006895Z","iopub.execute_input":"2025-08-06T10:58:24.007143Z","iopub.status.idle":"2025-08-06T10:58:24.264208Z","shell.execute_reply.started":"2025-08-06T10:58:24.007123Z","shell.execute_reply":"2025-08-06T10:58:24.263377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- For job seekers, it reveals which industries may be more competitive to break into.\n- For recruiters, it helps benchmark talent interest and assess if their sector is attracting enough visibility.","metadata":{}},{"cell_type":"markdown","source":"### 9. Companies Hiring in Each State","metadata":{}},{"cell_type":"code","source":"#Which companies are active in which states?\n\ncompany_state_jobs = updated_jobs.groupby(['companyName', 'state']).size().reset_index(name='jobCount')\n\ncompany_state_jobs = company_state_jobs.sort_values(by='jobCount', ascending=False)\n\ntop_company_state = company_state_jobs.head(10)\n\nax = sns.barplot(data=top_company_state, x='jobCount', y='companyName', hue='state', dodge=False, palette='crest')\n\nplt.title('Top Company-State Combinations by Job Count')\nplt.xlabel('Number of Listings')\nplt.ylabel('Company')\n\nfor container in ax.containers:\n    ax.bar_label(container, padding=3)\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:24.265077Z","iopub.execute_input":"2025-08-06T10:58:24.265340Z","iopub.status.idle":"2025-08-06T10:58:24.743648Z","shell.execute_reply.started":"2025-08-06T10:58:24.265321Z","shell.execute_reply":"2025-08-06T10:58:24.742795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- Job seekers understand which companies are hiring in which states — useful for location-specific targeting\n\n- Recruiters analyze regional hiring activity across major competitors\n\n","metadata":{}},{"cell_type":"markdown","source":"# Visual Exploration Summary – Version 4\n\nIn this version, I focused on turning the cleaned dataset into meaningful and useful visualizations using Seaborn and Matplotlib.  \nThe goal was not to make it look fancy — but to bring out trends that actually matter to either job seekers or recruiters.\n\n## 🔍 What I Did\n\n- Plotted the **top 10 hiring companies** to see who’s hiring the most.\n- Looked at the **contract type** and **experience level** distributions to understand what kind of roles are being posted.\n- Explored **sector-wise demand** (basic view) to see which industries are putting out the most jobs.\n- Checked **job posting activity over time** to spot any hiring patterns or slowdowns.\n- Visualized how **applications are spread** across listings — is competition high or balanced?\n- Plotted **total applications by sector** to see which industries are getting the most attention overall.\n- Added a **company + state combination chart** to see where hiring is happening geographically — who’s hiring and in which states.\n\n## ⚠️ What I Didn’t Cover\n\n- I skipped the `title` column in this version since the data is too messy and inconsistent. I’ll clean and explore it properly in **v5**.\n- I also skipped deeper analysis of the `sector` column (like cross-analysis with experience or applications) for now — that’ll also be part of the next version after cleanup.\n\n## 🎯 What I Learned\n\n- Even without touching the messy parts, you can still pull out 8–9 strong insights just by using visual tools smartly.\n- Adding visual context makes patterns easier to understand — especially when looking at competition levels, top companies, and hiring locations.\n- It's better to skip noisy columns than force weak charts — the real value comes from **clean, readable trends**.\n","metadata":{}},{"cell_type":"markdown","source":"# Notebook Version: v5\n\n**Focus** : Title & Sector Cleanup + Role-Based Insight Exploration\n\n**Overview:**\n\nIn this version, I shift focus to two key fields that were previously too messy to analyze meaningfully: **title** and **sector**.\nBoth of these columns carry crucial signals — job role, industry, and hiring focus — but in their raw form, they’re inconsistent, redundant, and often noisy.\n\n**Goal 🎯:**\n\nThe goal of this version is twofold:\n- Clean and categorize job titles into standard, analysis-ready buckets\n- Group sectors into simplified categories for clearer industry-level insights\n\n**Analysis Plan:**\n\nOnce cleaned, I’ll generate targeted visualizations to understand:\n- Which AI/ML roles are most in demand\n- Which sectors are hiring most actively\n- How roles and sectors intersect in real-world postings\n\nThis version is not about excessive plotting — it’s about preparing the data for smart role/sector trend analysis and enabling powerful filters in the next version.","metadata":{}},{"cell_type":"markdown","source":"### 1. Cleaning and Handling the Title column","metadata":{}},{"cell_type":"code","source":"# converting all the titles into lower case\n\njobs_df['title'] = jobs_df['title'].str.lower()\n\n# Grouping the titles into broad categories and few are termed as Others which are out of those categories\n\ndef clean_title(title):\n    if 'intern' in title:\n        return 'Intern'\n    elif 'ml ops' in title or 'mlops' in title or 'ops' in title:\n        return 'MLOps Engineer'\n    elif 'ai/ml' in title or 'ml/ai' in title or 'ai /ml' in title:\n        return 'AI/ML Engineer'\n    elif 'data scientist' in title or 'data' in title:\n        return 'Data Scientist'\n    elif 'deep learning' in title or 'dl' in title:\n        return 'Deep Learning Engineer'\n    elif 'nlp' in title:\n        return 'NLP Engineer'\n    elif 'computer vision' in title or 'cv' in title:\n        return 'Computer Vision Engineer'\n    elif 'research' in title:\n        return 'Research Engineer'\n    elif 'ai' in title or 'artificial intelligence' in title:\n        return 'AI Engineer'\n    elif 'ml' in title or 'machine learning' in title or 'machine' in title: \n        return 'Machine Learning Engineer'\n    elif 'python' in title:\n        return 'Python Engineer'\n    elif 'software' in title:\n        return 'Software Engineer (AI/ML)'\n    elif 'robots' in title or 'robotics' in title:\n        return 'Robotics Engineer'\n    elif 'front' in title or 'back' in title or 'web' in title:\n        return 'Web Development Engineer'\n    elif 'r&d' in title or 'RD' in title or 'Research' in title:\n        return 'Research and Development Engineer'\n    else:\n        return 'Other'\n\n# applying the function to the titles\ncleaned_title = jobs_df['title'].apply(clean_title)\n\n# changing the titles into cleaned titles\njobs_df['title'] = cleaned_title\n\n#converting the titles into title format\njobs_df['title'] = jobs_df['title'].str.title()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:24.744409Z","iopub.execute_input":"2025-08-06T10:58:24.744613Z","iopub.status.idle":"2025-08-06T10:58:24.755841Z","shell.execute_reply.started":"2025-08-06T10:58:24.744598Z","shell.execute_reply":"2025-08-06T10:58:24.754955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Cleaning and Handling the Sector Column","metadata":{}},{"cell_type":"code","source":"# converting all the sector values into lower case\n\njobs_df['sector'] = jobs_df['sector'].str.lower()\n\n# checking if sector column consists of any null values\njobs_df['sector'].isna().sum()\n\n# categorizing the sectors into broad categories\n\ndef clean_sector(sector):\n    \n    if 'tech' in sector or 'software' in sector or 'it' in sector or 'computer' in sector or 'data' in sector or 'telecommunication' in sector:\n        return 'Tech'\n\n    elif 'finance' in sector or 'bank' in sector or 'investment' in sector or 'insurance' in sector:\n        return 'Finance'\n\n    elif 'health' in sector or 'hospital' in sector or 'biotech' in sector or 'pharma' in sector or 'medical' in sector:\n        return 'Healthcare'\n\n    elif 'education' in sector or 'university' in sector or 'e-learning' in sector or 'school' in sector or 'coaching' in sector:\n        return 'Education'\n\n    elif 'government' in sector or 'public' in sector or 'defense' in sector:\n        return 'Government'\n\n    elif 'retail' in sector or 'ecommerce' in sector or 'consumer' in sector:\n        return 'Retail'\n\n    elif 'consult' in sector or 'advisory' in sector or 'services' in sector:\n        return 'Consulting'\n        \n    elif 'internet' in sector:\n        return 'Internet Publishing'\n\n    elif 'manufacturing' in sector or 'manufacturer' in sector:\n        return 'Manufacturing'\n\n    elif 'translation' in sector or 'localise' in sector:\n        return 'Translation and Localisation' \n\n    elif 'entertainment' in sector or 'entertaining' in sector or 'media' in sector:\n        return 'Entertainment'\n\n    elif 'engineer' in sector or 'engineering' in sector:\n        return 'Engineering'\n        \n    elif 'oil' in sector or 'gas' in sector:\n        return 'Energy'\n        \n    else:\n        return 'Other'\n\n#applying the function to each value in the sector\ncleaned_sector = jobs_df['sector'].apply(clean_sector) \n\n#checking the counts of different sectors\ncleaned_sector.value_counts()\n\n#adding the cleaned sector column to the dataframe\njobs_df['cleanedSector'] = cleaned_sector\n\n#converting the cleaned sectors name into title format\njobs_df['cleanedSector'] = jobs_df.cleanedSector.str.title()\n\n#converting the sectors name into title format\njobs_df['sector'] = jobs_df.sector.str.title()\njobs_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:24.756594Z","iopub.execute_input":"2025-08-06T10:58:24.756884Z","iopub.status.idle":"2025-08-06T10:58:24.794271Z","shell.execute_reply.started":"2025-08-06T10:58:24.756863Z","shell.execute_reply":"2025-08-06T10:58:24.793450Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n### TOP 10 JOB TITLES","metadata":{}},{"cell_type":"code","source":"# extracting the top 10 job titles from the df\ntop_titles = jobs_df.title.value_counts().head(10).reset_index()\n\n# plotting the chart\nax = sns.barplot(data=top_titles,x='count',y='title',palette='crest')\nplt.title('Top Ten Job Titles')\nplt.xlabel('Job Count')\nplt.ylabel('Job Titles')\n\nfor container in ax.containers:\n    ax.bar_label(container)\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:24.795017Z","iopub.execute_input":"2025-08-06T10:58:24.795261Z","iopub.status.idle":"2025-08-06T10:58:25.031874Z","shell.execute_reply.started":"2025-08-06T10:58:24.795236Z","shell.execute_reply":"2025-08-06T10:58:25.031056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Insight:\n\nData Scientist, AI/ML Engineer, and  Mlops Engineer dominate the hiring landscape.\nThese roles alone make up a significant share of all job postings, showing where demand is concentrated","metadata":{}},{"cell_type":"markdown","source":"### SECTOR WISE JOB DISTRIBUTION","metadata":{}},{"cell_type":"code","source":"sec = jobs_df.cleanedSector.value_counts().reset_index()\n\nax = sns.barplot(data=sec,y='cleanedSector',x='count',palette='crest')\nplt.title('Sector Wise Job Distribution')\nplt.xlabel('Job post for each sector')\nplt.ylabel('Sectors')\n\nfor container in ax.containers:\n    ax.bar_label(container)\n    \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:25.032887Z","iopub.execute_input":"2025-08-06T10:58:25.033231Z","iopub.status.idle":"2025-08-06T10:58:25.307610Z","shell.execute_reply.started":"2025-08-06T10:58:25.033196Z","shell.execute_reply":"2025-08-06T10:58:25.306732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Insight:\n\nTech sector is leading AI/ML hiring by a wide margin, followed by Consulting and Internet Publishing.\nThis reflects the deep integration of AI into core tech products.","metadata":{}},{"cell_type":"markdown","source":"### JOB ROLES ACROSS TOP 5 HIRING SECTORS","metadata":{}},{"cell_type":"code","source":"top_titles = jobs_df['title'].value_counts().head().index\ntop_sectors = jobs_df['cleanedSector'].value_counts().head().index\n\nfiltered_df = jobs_df[\n    jobs_df['title'].isin(top_titles) & \n    jobs_df['cleanedSector'].isin(top_sectors)\n]\n\nfiltered_ct = pd.crosstab(filtered_df['cleanedSector'], filtered_df['title'])\n\nplt.figure(figsize=(10,5))\nsns.heatmap(filtered_ct, annot=True, cmap=\"crest\", linewidths=0.5)\nplt.title(\"Top Roles vs Top Sectors\")\nplt.xlabel(\"Job Title\")\nplt.ylabel(\"Sector\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T10:58:25.308607Z","iopub.execute_input":"2025-08-06T10:58:25.308874Z","iopub.status.idle":"2025-08-06T10:58:25.615519Z","shell.execute_reply.started":"2025-08-06T10:58:25.308849Z","shell.execute_reply":"2025-08-06T10:58:25.614662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Insight:\n\nTech sector show the broadest role diversity, especially for ML Engineers and AI/ML Engineers","metadata":{}},{"cell_type":"markdown","source":"# Title & Sector Exploration Summary – Version 5\n\nIn this version, I tackled two of the messiest but most important fields in the dataset: **title** and **sector**.  \nBoth carry critical signals about what kinds of roles are in demand and which industries are hiring — but their raw formats were too inconsistent for any meaningful analysis.\n\n## 🔍 What I Did\n\n- Cleaned and standardized the title field using a custom rule-based function — grouped similar job titles into 15+ clear categories.\n- Simplified and grouped the sector field into broader categories like Tech, Finance, Healthcare, Government, etc.\n- Created new column `cleanedSector` for cleaner analysis for sectors.\n- Visualized the Top 10 job roles based on cleaned titles.\n- Explored sector-wise job distribution to see which industries are hiring the most.\n- Built a focused heatmap of top 5 sectors vs top 5 job roles to explore how hiring varies across industries.\n\n## ⚠️ What I Didn’t Cover\n\n- Didn’t go into advanced cross-analysis like title vs application counts, or experience level vs title\n- Skipped visualizing lower-ranked or rare titles/sectors to keep charts readable and insights focused.\n  \n## 🎯 What I Learned\n\n- Cleaning messy categorical text fields (like title/sector) unlocks meaningful analysis and smarter visuals.\n- Titles like \"Senior ML/AI Research Intern\" can now be grouped confidently under buckets like \"Intern\" or \"ML Engineer\", making analysis way more reliable.\n- Focused visualizations (like heatmaps on filtered data) are much more powerful than trying to show everything at once — **clarity > completeness.**\n","metadata":{}},{"cell_type":"markdown","source":"# Notebook Version: v6\n\n**Focus**: Job Roles, Experience Level & Real-World Application Pressure\n\n**Overview:**\n\nAfter cleaning and organizing job titles in the previous version, I wanted to take it a step further — not just see what roles exist, but understand **how they behave in the real market**.\n\nIn this version, I'm focusing on 3 things that matter when you're actually looking for a job:\n- What kind of roles are open to freshers?\n- Which roles are getting overcrowded with applicants?\n- And where's that sweet spot — roles that exist in good numbers but aren't flooded?\n\n**Goal 🎯:**\n\nThe goal here is to connect **roles**, **experience level**, and **application data** to see what's really going on underneath the surface.\n\nI want this to help someone decide:\n> “Is this job worth applying to?”","metadata":{}},{"cell_type":"markdown","source":"### 1. Job Role Distribution Across Experience Levels","metadata":{}},{"cell_type":"code","source":"top_roles = jobs_df['title'].value_counts().nlargest(10).index\nfiltered_df = jobs_df[jobs_df['title'].isin(top_roles)]\n\nax = sns.catplot(data=filtered_df,y='title',kind='count',col='experienceLevel',col_wrap = 4,order=filtered_df['title'].value_counts().index, palette='crest')\n\nax.set_titles(\"{col_name}\")\nax.set_axis_labels(\"Job Count\", \"Job Role\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:26:33.772457Z","iopub.execute_input":"2025-08-06T12:26:33.773177Z","iopub.status.idle":"2025-08-06T12:26:35.573199Z","shell.execute_reply.started":"2025-08-06T12:26:33.773148Z","shell.execute_reply":"2025-08-06T12:26:35.572329Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights: \n\n- Most of the roles demands **Mid-senior level** or **Entry level** experience\n- **Associate-level** roles are mostly limited to AI/ML Engineers as collective and idividually\n- ML Engineer appear across **all experience levels**, showing they’re in demand at every stage.\n- Most roles cluster at the **Mid-level**, confirming that companies prefer 2–4 years of experience in technical fields.\n- Almost every role does not demand a specific experience level thus anyone without experience can easily apply to these jobs.\n- **Executive Experience** and **Director Experience** are least required by the companies.\n","metadata":{}},{"cell_type":"markdown","source":"### 2. Average Applications per Job Role","metadata":{}},{"cell_type":"code","source":"title_application = jobs_df[['title','applicationsCount']]\ntitle_application \n# jobs_df\ngrouping = title_application.groupby('title').agg({'applicationsCount':'mean'})\ngrouping = grouping.sort_values(by='applicationsCount', ascending=False)\n\ngrouping_reset = grouping.reset_index()\n\nax = sns.barplot(data=grouping_reset, y='title', x='applicationsCount',palette='crest')\nplt.title(\"Average Applications per Job Role\")\nplt.xlabel(\"Job Role\")\nplt.ylabel(\"Avg Application Count\")\n\nfor container in ax.containers:\n    ax.bar_label(container)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T11:50:22.911896Z","iopub.execute_input":"2025-08-06T11:50:22.912211Z","iopub.status.idle":"2025-08-06T11:50:23.239224Z","shell.execute_reply.started":"2025-08-06T11:50:22.912186Z","shell.execute_reply":"2025-08-06T11:50:23.238387Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights\n\n- **Internships** receive the most applications (~200) — by far the most competitive.\n- **Software Engineer (AI/ML)** and **Web Dev** roles are more applied to than core ML roles, likely due to broader appeal.\n- **MLOps** and **AI/ML Engineers** are less applied to — these may be smart targets for qualified candidates.\n- **Deep Learning Engineers** receive the **least** attention (~66 apps), despite high relevance — a potential opportunity.\n- **\"Other\"** roles get skipped, showing the importance of clear, attractive job titles.\n","metadata":{}},{"cell_type":"markdown","source":"### 3. Job Count vs Avg Applications per Role","metadata":{}},{"cell_type":"code","source":"# Job count per role\njob_counts = jobs_df['title'].value_counts()\n\n# Avg applications per role\navg_apps = jobs_df.groupby('title')['applicationsCount'].mean()\n\n# Combine into one DataFrame (long format for sns)\ncomparison_df = pd.DataFrame({\n    'Job Count': job_counts,\n    'Avg Applications': avg_apps\n})\n\n# Keep only top 10 most common roles to reduce clutter\ntop_roles = job_counts.sort_values(ascending=False).head(10).index\ncomparison_df = comparison_df.loc[top_roles]\n\n# Reshape into long format\ncomparison_df_long = comparison_df.reset_index().melt(id_vars='title', value_vars=['Job Count', 'Avg Applications'],value_name='Value',var_name='Metric')\n\n# 4. Plot with seaborn\nplt.figure(figsize=(12,6))\nsns.barplot(data=comparison_df_long, x='title', y='Value', hue='Metric',palette='crest')\nplt.title(\"Job Count vs Avg Applications per Role\")\nplt.xlabel(\"Job Role\")\nplt.ylabel(\"Value\")\nplt.xticks(rotation=45)\nplt.legend(title='Metric')\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T12:37:33.735620Z","iopub.execute_input":"2025-08-06T12:37:33.736032Z","iopub.status.idle":"2025-08-06T12:37:34.057953Z","shell.execute_reply.started":"2025-08-06T12:37:33.736009Z","shell.execute_reply":"2025-08-06T12:37:34.057133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights:\n\n- **Machine Learning Engineer Role** have the **highest job counts** but the application count doesnot match them, not even 50% of the people apply for this role if compared with the jobs available.\n- **AI/ML Engineer Role** have a better ratio of openings and demands if compared with other job roles and their application count, indicating a healthy market position.\n- Most of the roles like **Software Engineer**, **Computer Vision Engineer** **NLP and Research Engineer** along with **Data Scientist** role have more average application count than the jobs available. \n- **Intern** role receives the most applications despite not having the highest number of openings — showing intense competition at the fresher level.\n- Roles like **Deep Learning Engineer** and **MLOps Engineer** have relatively **fewer applications** compared to others, even when job count is decent — making them **hidden opportunities** for skilled applicants.\n- This comparison clearly reveals where **supply-demand mismatch** exists, helping job seekers avoid wasting energy on over-applied roles.\n\n**Through this chart it can be concluded that job recruiters are more interested in hiring for ML roles however job seekers are applying to the other roles leading to an imbalance in ratio**\n","metadata":{}},{"cell_type":"markdown","source":"# Summary – Version 6\n\nAfter cleaning job titles in the last version, I wanted to understand **how these roles behave in the real world** — not just in volume, but in terms of experience requirements and application competition.\n\n## 🔍 What I Did\n\n- Explored how job roles are distributed across different **experience levels** (Entry, Mid, Senior, etc.)\n- Analyzed **average applications received per job title** to identify which roles are most and least competitive\n- Compared **job supply vs application demand** to uncover market imbalances and hidden opportunities\n\n## 📊 Charts I Built\n\n1. **Experience Level Distribution by Job Role** — to see which roles are fresher-friendly, mid-level focused, or spread across all levels  \n2. **Average Applications per Role** — to measure competition pressure across job types  \n3. **Job Count vs Avg Applications (Top Roles)** — a supply vs demand view to spot saturation vs opportunities\n\n## 🎯 What I Learned\n\n- Most roles fall under **Mid-level hiring** , reflecting companies’ strong preference for candidates with 2–4 years of experience.\n- **Internships** are the most applied-to roles (~200 apps), even without being the most available — proving just how tough the entry-level market is.\n- Roles like **MLOps Engineer** and **Deep Learning Engineer** get **very few applications**, despite relevance — making them smart targets for niche-skilled candidates.\n- Surprisingly, roles like **Software Engineer (AI/ML)** and **Web Development Engineer** receive more applications than core ML roles — possibly due to broader appeal or clearer job expectations.\n- When comparing job availability vs application demand, a clear imbalance shows up — **some roles are crowded, while others are overlooked**, despite healthy posting numbers.\n\n## 🧠 Big Takeaway\n\nThere’s a noticeable **mismatch between what companies are hiring for and what job seekers are chasing**.  \nIf you’re blindly applying to popular roles, chances are you’re just one of hundreds.  \nBut if you align your skills with under-applied, high-supply roles — you can massively improve your visibility and chances.\n\n## ✅ Why This Matters\n\nThis version wasn’t about flashy charts — it was about **real questions** that job seekers have:\n- “Where do I have the best shot?”\n- “Am I applying where companies are actually hiring?”\n- “Should I even be targeting this role at my level?”\n\nThat’s why this version is all about helping candidates **apply smarter**, not harder.\n","metadata":{}},{"cell_type":"markdown","source":"# Final Project Wrap-Up✨\n\nThis project was never about building the flashiest dashboard or running complex ML models.\n\nIt was about starting with messy, real-world data and asking the kind of questions that **job seekers actually care about**:\n- What roles are companies hiring for?\n- Who are they hiring — freshers or experienced folks?\n- Where is the competition intense, and where are the hidden opportunities?\n\nOver six versions, I cleaned messy job titles, grouped chaotic sectors, simplified noisy experience levels, and tied everything back to real-world hiring trends.\n\n\n## 💡 What I Learned\n\n- **Raw data doesn’t give answers — it gives friction.** But if you work through it, the clarity that follows is worth it.\n- Cleaning and structuring text fields like job titles is painful — but it's the key to every meaningful insight that followed.\n- One targeted chart, if designed with purpose, can be more powerful than ten generic ones.\n- EDA isn’t about quantity of code — it’s about **quality of thought**.\n\n\n## 🎯 What This Project Really Was\n\nThis wasn’t a textbook exercise.  \nIt was me, sitting with a messy dataset, trying to figure out how to **make it speak**.\n\nAnd in the process, I didn’t just learn about the job market — I learned how to:\n- Think more critically\n- Clean more confidently\n- Ask better questions\n- And extract value where there was once noise\n\n\n## ⚡ Closing Thought \n\nThis project wasn’t polished from the start — it was built version by version, through trial, errors, edits, and late realizations.\n\nBut that’s what made it valuable.\n\nI didn’t just run through a dataset — I stayed with it long enough to understand it, clean it, question it, and turn it into something that makes sense.\n\nIt’s not perfect. But it’s mine — and I walked away from it knowing more than when I began.\n\nThat, to me, is a win.\n\n","metadata":{}}]}